<!-- # LQR问题定义 -->
在LQR中我们通常优化一个代价函数
$$
J = \sum_{t=0}^{T-1} \left( x_t^\top Q x_t + u_t^\top R u_t \right) + x_T^\top Q_T x_T
$$
并满足线性系统
$$
x_{t+1}=Ax_t+Bu_t
$$
为了在对平方项求导时去掉系数 2，让推导更简洁，添加 $\tfrac{1}{2}$ 系数，不影响最优控制律或最终结果,
那么上述问题可以写为：
$$
\min_{\{u_0, u_1, \ldots, u_{N-1}\}} 
J = \tfrac{1}{2} \sum_{k=0}^{N-1} \left( x_k^\top Q x_k + u_k^\top R u_k \right)
+ \tfrac{1}{2} x_N^\top Q_N x_N
$$

其中系统满足
$$
x_{k+1}=Ax_k+Bu_k
$$

<!-- # Bellman递推 -->
要找到一个“最优策略”，也就是每个时刻该选什么 $u_k$，才能让 $J$ 最小

定义Bellman 方程（Bellman recursion）：
$$
V_k(x_k) = \min_{u_k} \left[ \ell_k(x_k, u_k) + V_{k+1}(x_{k+1}) \right]
$$
>其含义为：
“在状态 $x_k$ 时，未来总代价的最小值（ 记作 $V_k(x_k)$ ）等于——当前这一步的代价 + 从下一步开始的最优代价。”

其中，阶段代价$\ell_k(x_k, u_k)$为
$$
\ell_k(x_k, u_k) = \tfrac{1}{2} x_k^\top Q x_k + \tfrac{1}{2} u_k^\top R u_k
$$

终端代价为
$$
\tfrac{1}{2} \, x_N^\top Q_N x_N
$$

带入$x_{k+1}=Ax_k+Bu_k$,则上述方程可写为：
$$
\begin{aligned}
V_k(x_k) 
&= \min_{u_k} \left[ \ell_k(x_k, u_k) + V_{k+1}(x_{k+1}) \right] \\
&= \min_{u_k} \left[ \ell_k(x_k, u_k) + V_{k+1}(Ax_k+Bu_k) \right] \\
&= \min_{u_k} \left[ \tfrac{1}{2} x_k^\top Q x_k + \tfrac{1}{2} u_k^\top R u_k + V_{k+1}(Ax_k+Bu_k) \right]
\end{aligned}
$$

假设$V_{k+1}(x)=\tfrac{1}{2}x^\top P_{k+1}x$, 那么
$$
V_k(x_k) = \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}(A x_k + B u_k)^\top P_{k+1}(A x_k + B u_k)\Big]
$$
第三项展开过程如下
$$
\begin{aligned}
\tfrac{1}{2}(A x_k + B u_k)^\top & P_{k+1}(A x_k + B u_k) \\
&=\tfrac{1}{2}\Big( x_k^\top A^\top P_{k+1} A\, x_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; u_k^\top B^\top P_{k+1} A\, x_k
\;+\; u_k^\top B^\top P_{k+1} B\, u_k \Big)
\end{aligned}
$$


那么
$$
\begin{aligned}
V_k(x_k) 
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}(A x_k + B u_k)^\top P_{k+1}(A x_k + B u_k)\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}\Big( x_k^\top A^\top P_{k+1} A\, x_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; u_k^\top B^\top P_{k+1} A\, x_k
\;+\; u_k^\top B^\top P_{k+1} B\, u_k \Big)\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}\Big( x_k^\top A^\top P_{k+1} A\, x_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; u_k^\top B^\top P_{k+1} B\, u_k \Big)\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}\Big( x_k^\top A^\top P_{k+1} A\, x_k
\;+\; 2\,x_k^\top A^\top P_{k+1} B\, u_k
\;+\; u_k^\top B^\top P_{k+1} B\, u_k \Big)\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2} \, x_k^\top A^\top P_{k+1} A\, x_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; \tfrac{1}{2} \, u_k^\top B^\top P_{k+1} B\, u_k \Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P_{k+1} A) x_k + \tfrac{1}{2}u_k^\top R u_k 
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; \tfrac{1}{2} \, u_k^\top B^\top P_{k+1} B\, u_k \Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P_{k+1} A) x_k + \tfrac{1}{2}u_k^\top (R+B^\top P_{k+1} B) u_k 
\;+\; x_k^\top A^\top P_{k+1} B\, u_k\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P_{k+1} A) x_k + \tfrac{1}{2}u_k^\top (R+B^\top P_{k+1} B) u_k 
\;+\; u_k^\top B^\top P_{k+1} A\, x_k\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P_{k+1} A) x_k + u_k^\top (B^\top P_{k+1} A\,) x_k + \tfrac{1}{2}u_k^\top (R+B^\top P_{k+1} B) u_k 
\;\Big]
\end{aligned}
$$
令 $P=P_{k+1}$，那么
$$
\begin{aligned}
V_k(x_k) 
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P A) x_k + u_k^\top (B^\top P A\,) x_k + \tfrac{1}{2}u_k^\top (R+B^\top P B) u_k 
\;\Big]
\end{aligned}
$$

令：

$$
H_{xx}=Q+A^\top P A,\quad
H_{ux}=B^\top P A,\quad
H_{xu}=H_{ux}^\top=A^\top P B,\quad
H_{uu}=R+B^\top P B.
$$

则将其看作关于$u_k$的二次型

$$
\begin{aligned}
\phi(u_k)= \tfrac12 u_k^\top H_{uu} u_k + u_k^\top H_{ux} x_k + \tfrac12 x_k^\top H_{xx} x_k
\end{aligned}
$$

对 $u_k$ 求梯度（把 $x_k$ 当常量）,并令其等于0：

$$
\nabla_{u_k}\phi(u_k) = H_{uu}\,u_k + H_{ux}\,x_k = 0
$$
则可得：
$$
u_k^\star=-H_{uu}^{-1}H_{ux}x_k.
$$

令:
$$
K_k=H_{uu}^{-1}H_{ux}=(R+B^\top P B)^{-1}B^\top P A,
$$

则可给出反馈律
$$
u_k^\star = -K_k x_k = -H_{uu}^{-1}H_{ux}x_k
$$
并且
$$
\begin{aligned}
u_k^{\star\top}
&= \big(-\,H_{uu}^{-1}\,H_{ux}\,x_k\big)^\top \\
&= -\,x_k^\top\,H_{ux}^\top\,(H_{uu}^{-1})^\top \\
&= -\,x_k^\top\,H_{xu}\,(H_{uu}^\top)^{-1}.
\end{aligned}
$$

由于 $H_{uu}=R+B^\top P B$ 是对称正定的，所以 $H_{uu}^\top=H_{uu}$、$(H_{uu}^\top)^{-1}=H_{uu}^{-1}$

那么：
$$
\begin{aligned}
u_k^{\star\top}
&= -\,x_k^\top\,H_{xu}\,H_{uu}^{-1}
\end{aligned}
$$
将 $u_k^\star$ 代回 $\phi(u_k)$ 可得

$$
\begin{aligned}
\phi(u_k)
&= \tfrac12 x_k^\top H_{xx} x_k + u_k^{\star\top} H_{ux} x_k + \tfrac12 u_k^{\star\top} H_{uu} u_k^\star \\
&= \tfrac12 x_k^\top H_{xx} x_k + (-\,x_k^\top\,H_{xu}\,H_{uu}^{-1}) H_{ux} x_k + \tfrac12 (-\,x_k^\top\,H_{xu}\,H_{uu}^{-1}) H_{uu} (-H_{uu}^{-1}H_{ux}x_k) \\
&= \tfrac12 x_k^\top H_{xx} x_k -\,x_k^\top\,H_{xu}\,H_{uu}^{-1} H_{ux} x_k + \tfrac12 (x_k^\top\,H_{xu}\,H_{uu}^{-1}) H_{uu} (H_{uu}^{-1}H_{ux}x_k) \\
&= \tfrac12 x_k^\top H_{xx} x_k -\,x_k^\top\,H_{xu}\,H_{uu}^{-1} H_{ux} x_k + \tfrac12 x_k^\top\,H_{xu}\,H_{uu}^{-1} H_{ux}x_k \\
&= \tfrac12 x_k^\top H_{xx} x_k -\,\tfrac{1}{2}x_k^\top\,H_{xu}\,H_{uu}^{-1} H_{ux} x_k \\
&= \tfrac12 x_k^\top (H_{xx}-H_{xu}\,H_{uu}^{-1} H_{ux}) x_k 
\end{aligned}
$$

令 $P_k = H_{xx}-H_{xu}\,H_{uu}^{-1} H_{ux}$
则

$$
\begin{aligned}
P_k 
&= H_{xx}-H_{xu}\,H_{uu}^{-1} H_{ux} \\
&= Q+A^\top P A \;- A^\top P B(R+B^\top P B)^{-1}(B^\top P A)
\end{aligned}
$$

由于 $P=P_{k+1}$,那么：
$$
\begin{aligned}
P_k 
&= Q+A^\top P A \;- A^\top P B(R+B^\top P B)^{-1}(B^\top P A) \\
&= Q+A^\top P_{k+1} A \;- A^\top P_{k+1} B(R+B^\top P_{k+1} B)^{-1}(B^\top P_{k+1} A) 
\end{aligned}
$$

这就是标准Riccati:

$$
\begin{aligned}
P_k 
&= Q+A^\top P_{k+1} A \;- A^\top P_{k+1} B(R+B^\top P_{k+1} B)^{-1}(B^\top P_{k+1} A) 
\end{aligned}
$$
