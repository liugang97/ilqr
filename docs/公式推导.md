<!-- # LQR问题定义 -->
在LQR中我们通常优化一个代价函数
$$
J = \sum_{t=0}^{T-1} \left( x_t^\top Q x_t + u_t^\top R u_t \right) + x_T^\top Q_T x_T
$$
并满足线性系统
$$
x_{t+1}=Ax_t+Bu_t
$$
为了在对平方项求导时去掉系数 2，让推导更简洁，添加 $\tfrac{1}{2}$ 系数，不影响最优控制律或最终结果,
那么上述问题可以写为：
$$
\min_{\{u_0, u_1, \ldots, u_{N-1}\}} 
J = \tfrac{1}{2} \sum_{k=0}^{N-1} \left( x_k^\top Q x_k + u_k^\top R u_k \right)
+ \tfrac{1}{2} x_N^\top Q_N x_N
$$

其中系统满足
$$
x_{k+1}=Ax_k+Bu_k
$$

<!-- # Bellman递推 -->
要找到一个“最优策略”，也就是每个时刻该选什么 $u_k$，才能让 $J$ 最小

定义Bellman 方程（Bellman recursion）：
$$
V_k(x_k) = \min_{u_k} \left[ \ell_k(x_k, u_k) + V_{k+1}(x_{k+1}) \right]
$$
>其含义为：
“在状态 $x_k$ 时，未来总代价的最小值（ 记作 $V_k(x_k)$ ）等于——当前这一步的代价 + 从下一步开始的最优代价。”

其中，阶段代价$\ell_k(x_k, u_k)$为
$$
\ell_k(x_k, u_k) = \tfrac{1}{2} x_k^\top Q x_k + \tfrac{1}{2} u_k^\top R u_k
$$

终端代价为
$$
\tfrac{1}{2} \, x_N^\top Q_N x_N
$$

带入$x_{k+1}=Ax_k+Bu_k$,则上述方程可写为：
$$
\begin{aligned}
V_k(x_k) 
&= \min_{u_k} \left[ \ell_k(x_k, u_k) + V_{k+1}(x_{k+1}) \right] \\
&= \min_{u_k} \left[ \ell_k(x_k, u_k) + V_{k+1}(Ax_k+Bu_k) \right] \\
&= \min_{u_k} \left[ \tfrac{1}{2} x_k^\top Q x_k + \tfrac{1}{2} u_k^\top R u_k + V_{k+1}(Ax_k+Bu_k) \right]
\end{aligned}
$$

假设$V_{k+1}(x)=\tfrac{1}{2}x^\top P_{k+1}x$, 那么
$$
V_k(x_k) = \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}(A x_k + B u_k)^\top P_{k+1}(A x_k + B u_k)\Big]
$$
第三项展开过程如下
$$
\begin{aligned}
\tfrac{1}{2}(A x_k + B u_k)^\top & P_{k+1}(A x_k + B u_k) \\
&=\tfrac{1}{2}\Big( x_k^\top A^\top P_{k+1} A\, x_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; u_k^\top B^\top P_{k+1} A\, x_k
\;+\; u_k^\top B^\top P_{k+1} B\, u_k \Big)
\end{aligned}
$$


那么
$$
\begin{aligned}
V_k(x_k) 
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}(A x_k + B u_k)^\top P_{k+1}(A x_k + B u_k)\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}\Big( x_k^\top A^\top P_{k+1} A\, x_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; u_k^\top B^\top P_{k+1} A\, x_k
\;+\; u_k^\top B^\top P_{k+1} B\, u_k \Big)\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}\Big( x_k^\top A^\top P_{k+1} A\, x_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; u_k^\top B^\top P_{k+1} B\, u_k \Big)\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2}\Big( x_k^\top A^\top P_{k+1} A\, x_k
\;+\; 2\,x_k^\top A^\top P_{k+1} B\, u_k
\;+\; u_k^\top B^\top P_{k+1} B\, u_k \Big)\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top Q x_k + \tfrac{1}{2}u_k^\top R u_k + \tfrac{1}{2} \, x_k^\top A^\top P_{k+1} A\, x_k
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; \tfrac{1}{2} \, u_k^\top B^\top P_{k+1} B\, u_k \Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P_{k+1} A) x_k + \tfrac{1}{2}u_k^\top R u_k 
\;+\; x_k^\top A^\top P_{k+1} B\, u_k
\;+\; \tfrac{1}{2} \, u_k^\top B^\top P_{k+1} B\, u_k \Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P_{k+1} A) x_k + \tfrac{1}{2}u_k^\top (R+B^\top P_{k+1} B) u_k 
\;+\; x_k^\top A^\top P_{k+1} B\, u_k\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P_{k+1} A) x_k + \tfrac{1}{2}u_k^\top (R+B^\top P_{k+1} B) u_k 
\;+\; u_k^\top B^\top P_{k+1} A\, x_k\Big] \\
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P_{k+1} A) x_k + u_k^\top (B^\top P_{k+1} A\,) x_k + \tfrac{1}{2}u_k^\top (R+B^\top P_{k+1} B) u_k 
\;\Big]
\end{aligned}
$$
令 $P=P_{k+1}$，那么
$$
\begin{aligned}
V_k(x_k) 
&= \min_{u_k}\Big[\tfrac{1}{2}x_k^\top (Q+A^\top P A) x_k + u_k^\top (B^\top P A\,) x_k + \tfrac{1}{2}u_k^\top (R+B^\top P B) u_k 
\;\Big]
\end{aligned}
$$

令：

$$
H_{xx}=Q+A^\top P A,\quad
H_{ux}=B^\top P A,\quad
H_{xu}=H_{ux}^\top=A^\top P B,\quad
H_{uu}=R+B^\top P B.
$$

则将其看作关于$u_k$的二次型

$$
\begin{aligned}
\phi(u_k)= \tfrac12 u_k^\top H_{uu} u_k + u_k^\top H_{ux} x_k + \tfrac12 x_k^\top H_{xx} x_k
\end{aligned}
$$

对 $u_k$ 求梯度（把 $x_k$ 当常量）,并令其等于0：

$$
\nabla_{u_k}\phi(u_k) = H_{uu}\,u_k + H_{ux}\,x_k = 0
$$
则可得：
$$
u_k^\star=-H_{uu}^{-1}H_{ux}x_k.
$$

令:
$$
K_k=H_{uu}^{-1}H_{ux}=(R+B^\top P B)^{-1}B^\top P A,
$$

则可给出反馈律
$$
u_k^\star = -K_k x_k = -H_{uu}^{-1}H_{ux}x_k
$$
并且
$$
\begin{aligned}
u_k^{\star\top}
&= \big(-\,H_{uu}^{-1}\,H_{ux}\,x_k\big)^\top \\
&= -\,x_k^\top\,H_{ux}^\top\,(H_{uu}^{-1})^\top \\
&= -\,x_k^\top\,H_{xu}\,(H_{uu}^\top)^{-1}.
\end{aligned}
$$

由于 $H_{uu}=R+B^\top P B$ 是对称正定的，所以 $H_{uu}^\top=H_{uu}$、$(H_{uu}^\top)^{-1}=H_{uu}^{-1}$

那么：
$$
\begin{aligned}
u_k^{\star\top}
&= -\,x_k^\top\,H_{xu}\,H_{uu}^{-1}
\end{aligned}
$$
将 $u_k^\star$ 代回 $\phi(u_k)$ 可得

$$
\begin{aligned}
\phi(u_k)
&= \tfrac12 x_k^\top H_{xx} x_k + u_k^{\star\top} H_{ux} x_k + \tfrac12 u_k^{\star\top} H_{uu} u_k^\star \\
&= \tfrac12 x_k^\top H_{xx} x_k + (-\,x_k^\top\,H_{xu}\,H_{uu}^{-1}) H_{ux} x_k + \tfrac12 (-\,x_k^\top\,H_{xu}\,H_{uu}^{-1}) H_{uu} (-H_{uu}^{-1}H_{ux}x_k) \\
&= \tfrac12 x_k^\top H_{xx} x_k -\,x_k^\top\,H_{xu}\,H_{uu}^{-1} H_{ux} x_k + \tfrac12 (x_k^\top\,H_{xu}\,H_{uu}^{-1}) H_{uu} (H_{uu}^{-1}H_{ux}x_k) \\
&= \tfrac12 x_k^\top H_{xx} x_k -\,x_k^\top\,H_{xu}\,H_{uu}^{-1} H_{ux} x_k + \tfrac12 x_k^\top\,H_{xu}\,H_{uu}^{-1} H_{ux}x_k \\
&= \tfrac12 x_k^\top H_{xx} x_k -\,\tfrac{1}{2}x_k^\top\,H_{xu}\,H_{uu}^{-1} H_{ux} x_k \\
&= \tfrac12 x_k^\top (H_{xx}-H_{xu}\,H_{uu}^{-1} H_{ux}) x_k 
\end{aligned}
$$

令 $P_k = H_{xx}-H_{xu}\,H_{uu}^{-1} H_{ux}$
则

$$
\begin{aligned}
P_k 
&= H_{xx}-H_{xu}\,H_{uu}^{-1} H_{ux} \\
&= Q+A^\top P A \;- A^\top P B(R+B^\top P B)^{-1}(B^\top P A)
\end{aligned}
$$

由于 $P=P_{k+1}$,那么：
$$
\begin{aligned}
P_k 
&= Q+A^\top P A \;- A^\top P B(R+B^\top P B)^{-1}(B^\top P A) \\
&= Q+A^\top P_{k+1} A \;- A^\top P_{k+1} B(R+B^\top P_{k+1} B)^{-1}(B^\top P_{k+1} A) 
\end{aligned}
$$

这就是标准离散时间Riccati方程:

$$
\begin{aligned}
P_k 
&= Q+A^\top P_{k+1} A \;- A^\top P_{k+1} B(R+B^\top P_{k+1} B)^{-1}(B^\top P_{k+1} A) 
\end{aligned}
$$
<!-- # LQR推导结论的使用方法 -->
上述推导结果的使用如下：

已知终止条件，在时间终点 $N$:
$$
P_N = Q_N
$$
终端代价$V_N(x_N)$如下：
$$
V_N(x_N)= \tfrac{1}{2} x_N^\top Q_N x_N
$$

向后计算（Backward pass）：

按照 $k=N-1,N-2,...,0$ 的顺序，用上述Riccati方程计算每个$P_k$

计算反馈增益矩阵

$$
K_k=(R+B^\top P_{k+1} B)^{-1}B^\top P_{k+1} A
$$

那么，在状态$x_k$时，最优控制为:
$$
u_k^\star=-K_kx_k
$$

最后进行正向模拟（Forward pass）：

从初始状态$x_0$出发，用
$$
x_{k+1}=(A-BK_k)x_k
$$
逐步得到整个最优轨迹。

<!-- # 从LQR到ILQR -->
------
在LQR中，动力学是线性的：
iLQR 的动力学模型是非线性的：
$$
x_{k+1}=Ax_k+Bu_k
$$
代价是二次的：
$$
\ell_k(x_k, u_k) = \tfrac{1}{2} x_k^\top Q x_k + \tfrac{1}{2} u_k^\top R u_k
$$
这样可以直接求解解析解。
而对于更为常见的情况下的动力学，一般为非线性函数：
$$
x_{k+1}=f(x_k+u_k)
$$
而代价也可能是非线性的：
$$
\ell(x_k, u_k)
= (x_k - x_{\text{goal}})^\top Q (x_k - x_{\text{goal}})
+ \text{其它非线性项}
$$
非线性函数无法直接求导及最优解，因此在某个“参考轨迹”附近，用泰勒展开做局部近似。

首先，对动力学进行线性化，只保留一阶项，在当前轨迹 $(x_k,u_k)$ 附近,考虑微小扰动：

$$
\delta x_k = x_k^{\text{new}} - x_k, 
\quad
\delta u_k = u_k^{\text{new}} - u_k
$$

对 $f(x,u)$ 做一阶泰勒展开：
$$
f(x_k + \delta x_k,\, u_k + \delta u_k)
\;\approx\;
f(x_k, u_k)
+ \frac{\partial f}{\partial x}\Big|_{(x_k,\,u_k)} \delta x_k
+ \frac{\partial f}{\partial u}\Big|_{(x_k,\,u_k)} \delta u_k
$$

于是线性化动力学变成：
$$
\delta x_{k+1}
\; = \;
f(x_k + \delta x_k,\, u_k + \delta u_k)
\; - \;
f(x_k, u_k)
\;\approx\;
\frac{\partial f}{\partial x}\Big|_{(x_k,\,u_k)} \delta x_k
+ \frac{\partial f}{\partial u}\Big|_{(x_k,\,u_k)} \delta u_k
$$
令：

$$
A_k = \frac{\partial f}{\partial x}\Big|_{(x_k,\,u_k)}
\quad
B_k = \frac{\partial f}{\partial u}\Big|_{(x_k,\,u_k)}
$$

则可得：
$$
\delta x_{k+1} \;\approx\; A_k\, \delta x_k + B_k\, \delta u_k
$$

然后对二次代价函数求近似，保留到二阶项，对代价 $\ell_k(x_k,u_k)$ 做泰勒展开：

$$
\ell_k(x_k + \delta x,\, u_k + \delta u_k)
\;\approx\;
\ell_k
+ \ell_x^\top \delta x_k
+ \ell_u^\top \delta u_k
+ \tfrac{1}{2}
\begin{bmatrix}
\delta x_k \\[3pt]
\delta u_k
\end{bmatrix}^\top
\begin{bmatrix}
\ell_{xx} & \ell_{xu} \\[3pt]
\ell_{ux} & \ell_{uu}
\end{bmatrix}
\begin{bmatrix}
\delta x_k \\[3pt]
\delta u_k
\end{bmatrix}
$$

把非线性问题近似成了一个局部的线性-二次问题

- 动力学一阶线性化
- 代价函数二阶近似

在名义轨迹附近对“值函数” $V_k(x_k)$ 做二阶泰勒召开

LQR中，$V_k(x_k)$ 是一个二次型：
$$
V_k(x_k) = \tfrac{1}{2}\, x_k^\top P_k\, x_k
$$

在iLQR中，对于非线性系统，只能做近似，存在微小扰动 $\delta_k$ 时，采用二阶泰勒展开：
$$
V_k(x_k + \delta x_k)
\;\approx\;
V_k(x_k)
+ \frac{\partial V_k}{\partial x}\Big|_{x_k}^\top \delta x_k
+ \tfrac{1}{2}\, \delta x_k^\top
\frac{\partial^2 V_k}{\partial x^2}\Big|_{x_k}
\delta x_k
$$

可得：
$$
\delta V_k(\delta x_k) \; = \;  V_k(x_k + \delta x_k) -V_k(x_k)
\;\approx\;
 \frac{\partial V_k}{\partial x}\Big|_{x_k}^\top \delta x_k
+ \tfrac{1}{2}\, \delta x_k^\top
\frac{\partial^2 V_k}{\partial x^2}\Big|_{x_k}
\delta x_k
$$

令：
$$
p_k = \frac{\partial V_k}{\partial x}\Big|_{x_k}, 
\quad
P_k = \frac{\partial^2 V_k}{\partial x^2}\Big|_{x_k}
$$

则可得：
$$
\delta V_k(\delta x_k)
\;\approx\;
\tfrac{1}{2}\, \delta x_k^\top P_k\, \delta x_k
+ p_k^\top \delta x_k
$$

终端项：

$$
V_N(x_N) = \ell_N(x_N)
$$
在状态 $x_N$ 处对其进行泰勒展开：
$$
\ell_N(x_N + \delta x_N)
\;\approx\;
\ell_N(x_N)
+ (\ell_N)_x^\top \delta x_N
+ \tfrac{1}{2}\, \delta x_N^\top (\ell_N)_{xx}\, \delta x_N
$$
因此，终端项：
$$
P_N = \ell_{N,xx}, 
\quad
p_N = \ell_{N,x}
$$

根据Bellman关系，每个时间步的代价可以递推地写成：
$$
V_k(x_k)
= \min_{u_k}
\Big[
\,\ell_k(x_k, u_k)
+ V_{k+1}\big(f(x_k, u_k)\big)
\Big]
$$

>当前这一步的总代价=当前步代+未来所有步的总代价。

定义Q函数为
$$
Q_k(x_k, u_k)
= \ell_k(x_k, u_k)
+ V_{k+1}\big(f(x_k, u_k)\big)
$$

在iLQR中，需要做“线性化+二次近似”，在某条参考轨迹的 $(x_k,u_k)$ 附近，考虑小扰动：
$$
\delta x_k = x_k^{\text{new}} - x_k,
\quad
\delta u_k = u_k^{\text{new}} - u_k
$$

